{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RZOuS9LWQvv"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %pip install tf-nightly\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMHwYXHXCar3"
      },
      "outputs": [],
      "source": [
        "# get data files\n",
        "!wget https://cdn.freecodecamp.org/project-data/sms/train-data.tsv\n",
        "!wget https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv\n",
        "\n",
        "train_file_path = \"train-data.tsv\"\n",
        "test_file_path = \"valid-data.tsv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_h508FEClxO"
      },
      "outputs": [],
      "source": [
        "# read data\n",
        "train_data = pd.read_csv(train_file_path, sep=\"\\t\", header=None)\n",
        "test_data = pd.read_csv(test_file_path, sep=\"\\t\", header=None)\n",
        "\n",
        "print(\"Original data:\")\n",
        "print(\"Train data shape:\", train_data.shape)\n",
        "print(\"Test data shape:\", test_data.shape)\n",
        "print(\"\\nTrain data label distribution:\\n\", train_data[0].value_counts())\n",
        "print(\"\\nTest data label distribution:\\n\", test_data[0].value_counts())\n",
        "\n",
        "# Map labels\n",
        "train_data[0] = train_data[0].map({'ham': 0, 'spam': 1})\n",
        "test_data[0] = test_data[0].map({'ham': 0, 'spam': 1})\n",
        "\n",
        "# Check after mapping\n",
        "print(\"\\nAfter mapping:\")\n",
        "print(train_data.head())\n",
        "print(test_data.head())\n",
        "print(\"\\nTrain data label distribution:\\n\", train_data[0].value_counts())\n",
        "print(\"\\nTest data label distribution:\\n\", test_data[0].value_counts())\n",
        "\n",
        "# Remove NaN values\n",
        "train_data = train_data.dropna()\n",
        "test_data = test_data.dropna()\n",
        "\n",
        "# Check after removing NaN values\n",
        "print(\"\\nAfter removing NaN:\")\n",
        "print(\"Train data shape:\", train_data.shape)\n",
        "print(\"Test data shape:\", test_data.shape)\n",
        "print(\"\\nTrain data label distribution:\\n\", train_data[0].value_counts())\n",
        "print(\"\\nTest data label distribution:\\n\", test_data[0].value_counts())\n",
        "\n",
        "# If data is not empty, proceed with tokenization and padding\n",
        "if len(train_data) > 0 and len(test_data) > 0:\n",
        "    # Convert text data to lists\n",
        "    train_data_text = train_data[1].tolist()\n",
        "    train_data_label = train_data[0].tolist()\n",
        "    test_data_text = test_data[1].tolist()\n",
        "    test_data_label = test_data[0].tolist()\n",
        "\n",
        "    # Tokenize and pad sequences\n",
        "\n",
        "    max_words = 1300\n",
        "    max_length = 100\n",
        "\n",
        "    tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
        "    tokenizer.fit_on_texts(train_data_text)\n",
        "\n",
        "    train_sequences = tokenizer.texts_to_sequences(train_data_text)\n",
        "    test_sequences = tokenizer.texts_to_sequences(test_data_text)\n",
        "\n",
        "    train_padded = pad_sequences(train_sequences, maxlen=max_length, padding='post', truncating='post')\n",
        "    test_padded = pad_sequences(test_sequences, maxlen=max_length, padding='post', truncating='post')\n",
        "\n",
        "    # Convert labels to numpy arrays\n",
        "    train_labels = np.array(train_data_label)\n",
        "    test_labels = np.array(test_data_label)\n",
        "\n",
        "    # Check final shapes\n",
        "    print(\"\\nFinal shapes:\")\n",
        "    print(\"train_padded shape:\", train_padded.shape)\n",
        "    print(\"train_labels shape:\", train_labels.shape)\n",
        "    print(\"test_padded shape:\", test_padded.shape)\n",
        "    print(\"test_labels shape:\", test_labels.shape)\n",
        "    \n",
        "    print(\"\\nFinal label distribution:\")\n",
        "    print(\"Train labels:\\n\", np.unique(train_labels, return_counts=True))\n",
        "    print(\"Test labels:\\n\", np.unique(test_labels, return_counts=True))\n",
        "else:\n",
        "    print(\"Data is empty after preprocessing!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOMKywn4zReN"
      },
      "outputs": [],
      "source": [
        "# Define the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(len(tokenizer.word_index)+1, 32, input_length=max_length),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16)),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_padded, train_labels, epochs=10, \n",
        "                    validation_data=(test_padded, test_labels),\n",
        "                    batch_size=32)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_padded, test_labels, verbose=2)\n",
        "print(f\"Test accuracy: {test_acc}\")\n",
        "\n",
        "# Plot training history\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9tD9yACG6M9"
      },
      "outputs": [],
      "source": [
        "# function to predict messages based on model\n",
        "# (should return list containing prediction and label, ex. [0.008318834938108921, 'ham'])\n",
        "def predict_message(message):\n",
        "    # Tokenize and pad the message\n",
        "    sequence = tokenizer.texts_to_sequences([message])\n",
        "    padded = pad_sequences(sequence, maxlen=max_length, padding='post', truncating='post')\n",
        "    \n",
        "    # Make prediction\n",
        "    prediction = model.predict(padded)[0][0]\n",
        "    \n",
        "    # Convert prediction to label\n",
        "    label = \"spam\" if prediction > 0.5 else \"ham\"\n",
        "    \n",
        "    return (prediction, label)\n",
        "\n",
        "pred_text = \"i'll bring it tomorrow. don't forget the milk\"\n",
        "\n",
        "prediction = predict_message(pred_text)\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dxotov85SjsC"
      },
      "outputs": [],
      "source": [
        "# Run this cell to test your function and model. Do not modify contents.\n",
        "def test_predictions():\n",
        "  test_messages = [\"how are you doing today\",\n",
        "                   \"sale today! to stop texts call 98912460324\",\n",
        "                   \"i dont want to go. can we try it a different day? available sat\",\n",
        "                   \"our new mobile video service is live. just install on your phone to start watching.\",\n",
        "                   \"you have won Â£1000 cash! call to claim your prize.\",\n",
        "                   \"i'll bring it tomorrow. don't forget the milk.\",\n",
        "                   \"wow, is your arm alright. that happened to me one time too\"\n",
        "                  ]\n",
        "\n",
        "  test_answers = [\"ham\", \"spam\", \"ham\", \"spam\", \"spam\", \"ham\", \"ham\"]\n",
        "  passed = True\n",
        "\n",
        "  for msg, ans in zip(test_messages, test_answers):\n",
        "    prediction = predict_message(msg)\n",
        "    if prediction[1] != ans:\n",
        "      passed = False\n",
        "\n",
        "  if passed:\n",
        "    print(\"You passed the challenge. Great job!\")\n",
        "  else:\n",
        "    print(\"You haven't passed yet. Keep trying.\")\n",
        "\n",
        "test_predictions()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
